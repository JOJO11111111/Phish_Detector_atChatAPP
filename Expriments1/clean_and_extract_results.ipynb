{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60cecf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (2.2.4)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    "%pip install pandas numpy matplotlib scikit-learn seaborn tqdm\n",
    "\n",
    "# Import Block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea3d365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category: benign_with_logo\n",
      "  Multimodal predictions count: 242 (Unique URLs: 242)\n",
      "  Original predictions count: 249 (Unique URLs: 249)\n",
      "  Common predicted samples count: 241\n",
      "\n",
      "Category: benign_without_logo\n",
      "  Multimodal predictions count: 250 (Unique URLs: 250)\n",
      "  Original predictions count: 249 (Unique URLs: 249)\n",
      "  Common predicted samples count: 249\n",
      "\n",
      "Category: Fresh_Logo_Phishing\n",
      "  Multimodal predictions count: 238 (Unique URLs: 238)\n",
      "  Original predictions count: 225 (Unique URLs: 225)\n",
      "  Common predicted samples count: 225\n",
      "\n",
      "Category: Learned_Logo_Phishing\n",
      "  Multimodal predictions count: 244 (Unique URLs: 244)\n",
      "  Original predictions count: 239 (Unique URLs: 239)\n",
      "  Common predicted samples count: 239\n",
      "\n",
      "Category: No_Logo_Phishing\n",
      "  Multimodal predictions count: 230 (Unique URLs: 230)\n",
      "  Original predictions count: 228 (Unique URLs: 228)\n",
      "  Common predicted samples count: 222\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define file paths for each category\n",
    "categories = {\n",
    "    \"benign_with_logo\": {\n",
    "         \"multimodal\": \"/home/tiffanybao/PhishIntention/results/4.11/Multimodal/benign_with_logo_predict.csv\",\n",
    "         \"original\":   \"/home/tiffanybao/PhishIntention/results/4.11/Original/benign_with_logo_predict.txt\"\n",
    "    },\n",
    "    \"benign_without_logo\": {\n",
    "         \"multimodal\": \"/home/tiffanybao/PhishIntention/results/4.11/Multimodal/benign_without_logo_predict.csv\",\n",
    "         \"original\":   \"/home/tiffanybao/PhishIntention/results/4.11/Original/benign_without_logo_predict.txt\"\n",
    "    },\n",
    "    \"Fresh_Logo_Phishing\": {\n",
    "         \"multimodal\": \"/home/tiffanybao/PhishIntention/results/4.11/Multimodal/Fresh_Logo_Phishing_predict.csv\",\n",
    "         \"original\":   \"/home/tiffanybao/PhishIntention/results/4.11/Original/Fresh_Logo_Phishing_predict.txt\"\n",
    "    },\n",
    "    \"Learned_Logo_Phishing\": {\n",
    "         \"multimodal\": \"/home/tiffanybao/PhishIntention/results/4.11/Multimodal/Learned_Logo_Phishing_predict.csv\",\n",
    "         \"original\":   \"/home/tiffanybao/PhishIntention/results/4.11/Original/Learned_Logo_Phishing_predict.txt\"\n",
    "    },\n",
    "    \"No_Logo_Phishing\": {\n",
    "         \"multimodal\": \"/home/tiffanybao/PhishIntention/results/4.11/Multimodal/No_Logo_Phishing_predict.csv\",\n",
    "         \"original\":   \"/home/tiffanybao/PhishIntention/results/4.11/Original/No_Logo_Phishing_predict.txt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def load_multimodal_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads a CSV file from the multimodal predictions.\n",
    "    Assumes a header is available. Renames column if necessary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Standardize URL column name if needed\n",
    "        if 'url' not in df.columns and 'URL' in df.columns:\n",
    "            df = df.rename(columns={\"URL\": \"url\"})\n",
    "            \n",
    "        return df.drop_duplicates(subset=[\"url\"])\n",
    "        # return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading multimodal file {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_original_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads a TXT file from the original (Phishintention) predictions.\n",
    "    Expects a tab-separated file with no header.\n",
    "    The expected order is:\n",
    "      folder, url, phish_category, pred_target, matched_domain, siamese_conf\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\", header=None, encoding='ISO-8859-1')\n",
    "        df.columns = [\"folder\", \"url\", \"phish_category\", \"pred_target\", \"matched_domain\", \"siamese_conf\"]\n",
    "        return df.drop_duplicates(subset=[\"url\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading original file {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Loop through each category, load files, and compute the counts\n",
    "for category, paths in categories.items():\n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    \n",
    "    # Load multimodal predictions\n",
    "    mm_path = paths[\"multimodal\"]\n",
    "    mm_df = load_multimodal_file(mm_path)\n",
    "    mm_count = len(mm_df)\n",
    "    mm_unique = len(mm_df[\"url\"].dropna().unique())\n",
    "    print(f\"  Multimodal predictions count: {mm_count} (Unique URLs: {mm_unique})\")\n",
    "    \n",
    "    # Load original predictions if available\n",
    "    orig_path = paths[\"original\"]\n",
    "    if orig_path is not None:\n",
    "        orig_df = load_original_file(orig_path)\n",
    "        orig_count = len(orig_df)\n",
    "        orig_unique = len(orig_df[\"url\"].dropna().unique())\n",
    "        print(f\"  Original predictions count: {orig_count} (Unique URLs: {orig_unique})\")\n",
    "        \n",
    "        # Calculate common samples based on unique URLs\n",
    "        mm_urls = set(mm_df[\"url\"].dropna().unique())\n",
    "        orig_urls = set(orig_df[\"url\"].dropna().unique())\n",
    "        common_urls = mm_urls.intersection(orig_urls)\n",
    "        print(f\"  Common predicted samples count: {len(common_urls)}\")\n",
    "    else:\n",
    "        print(\"  Original predictions not available for this category.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23071af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category: benign_with_logo\n",
      "  Common predicted samples count: 241\n",
      "  Multimodal common DataFrame shape: (241, 10)\n",
      "  Original common DataFrame shape: (241, 6)\n",
      "\n",
      "Category: benign_without_logo\n",
      "  Common predicted samples count: 249\n",
      "  Multimodal common DataFrame shape: (249, 10)\n",
      "  Original common DataFrame shape: (249, 6)\n",
      "\n",
      "Category: Fresh_Logo_Phishing\n",
      "  Common predicted samples count: 225\n",
      "  Multimodal common DataFrame shape: (225, 10)\n",
      "  Original common DataFrame shape: (225, 6)\n",
      "\n",
      "Category: Learned_Logo_Phishing\n",
      "  Common predicted samples count: 239\n",
      "  Multimodal common DataFrame shape: (239, 10)\n",
      "  Original common DataFrame shape: (239, 6)\n",
      "\n",
      "Category: No_Logo_Phishing\n",
      "  Common predicted samples count: 222\n",
      "  Multimodal common DataFrame shape: (222, 10)\n",
      "  Original common DataFrame shape: (222, 6)\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store the common DataFrames for each category\n",
    "multi_common_dfs = {}\n",
    "ori_common_dfs = {}\n",
    "\n",
    "# Loop over each category, load the data and filter only rows whose URLs are common in both model outputs\n",
    "for category, paths in categories.items():\n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    \n",
    "    # Load multimodal predictions (CSV)\n",
    "    mm_df = load_multimodal_file(paths[\"multimodal\"])\n",
    "    # For original predictions, load the TXT file (if available)\n",
    "    if paths[\"original\"] is not None:\n",
    "        orig_df = load_original_file(paths[\"original\"])\n",
    "    else:\n",
    "        orig_df = pd.DataFrame()\n",
    "    \n",
    "    # Get the unique URL sets from each DataFrame\n",
    "    mm_urls = set(mm_df[\"url\"].dropna().unique())\n",
    "    ori_urls = set(orig_df[\"url\"].dropna().unique()) if not orig_df.empty else set()\n",
    "    \n",
    "    # Compute the common URLs (intersection)\n",
    "    common_urls = mm_urls.intersection(ori_urls)\n",
    "    print(f\"  Common predicted samples count: {len(common_urls)}\")\n",
    "    \n",
    "    # Filter the multimodal DataFrame: extract rows corresponding to common URLs\n",
    "    mm_common_df = mm_df[mm_df[\"url\"].isin(common_urls)].copy()\n",
    "    # Similarly filter the original DataFrame, if available\n",
    "    ori_common_df = orig_df[orig_df[\"url\"].isin(common_urls)].copy() if not orig_df.empty else pd.DataFrame()\n",
    "    \n",
    "    # Store the filtered DataFrames in the dictionaries\n",
    "    multi_common_dfs[category] = mm_common_df\n",
    "    ori_common_dfs[category] = ori_common_df\n",
    "    \n",
    "    # Create global variables with descriptive names for ease of reference.\n",
    "    # For example, for \"benign_with_logo\", we'll create \"multi_common_benign_with_logo\" and \"ori_common_benign_with_logo\".\n",
    "    global_var_multi = f\"multi_common_{category.lower()}\"\n",
    "    global_var_ori   = f\"ori_common_{category.lower()}\"\n",
    "    globals()[global_var_multi] = mm_common_df\n",
    "    globals()[global_var_ori] = ori_common_df\n",
    "    \n",
    "    print(f\"  Multimodal common DataFrame shape: {mm_common_df.shape}\")\n",
    "    if not ori_common_df.empty:\n",
    "        print(f\"  Original common DataFrame shape: {ori_common_df.shape}\")\n",
    "    else:\n",
    "        print(\"  No original DataFrame available for this category.\")\n",
    "        \n",
    "# Example of checking one of the created global variables:\n",
    "# print(\"\\nExample: multi_common_benign_with_logo shape:\", multi_common_benign_with_logo.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ac03677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved multimodal common DataFrame for 'benign_with_logo' to /home/tiffanybao/PhishIntention/results/4.12/multi_common_benign_with_logo.csv\n",
      "Saved multimodal common DataFrame for 'benign_without_logo' to /home/tiffanybao/PhishIntention/results/4.12/multi_common_benign_without_logo.csv\n",
      "Saved multimodal common DataFrame for 'Fresh_Logo_Phishing' to /home/tiffanybao/PhishIntention/results/4.12/multi_common_Fresh_Logo_Phishing.csv\n",
      "Saved multimodal common DataFrame for 'Learned_Logo_Phishing' to /home/tiffanybao/PhishIntention/results/4.12/multi_common_Learned_Logo_Phishing.csv\n",
      "Saved multimodal common DataFrame for 'No_Logo_Phishing' to /home/tiffanybao/PhishIntention/results/4.12/multi_common_No_Logo_Phishing.csv\n",
      "Saved original common DataFrame for 'benign_with_logo' to /home/tiffanybao/PhishIntention/results/4.12/ori_common_benign_with_logo.csv\n",
      "Saved original common DataFrame for 'benign_without_logo' to /home/tiffanybao/PhishIntention/results/4.12/ori_common_benign_without_logo.csv\n",
      "Saved original common DataFrame for 'Fresh_Logo_Phishing' to /home/tiffanybao/PhishIntention/results/4.12/ori_common_Fresh_Logo_Phishing.csv\n",
      "Saved original common DataFrame for 'Learned_Logo_Phishing' to /home/tiffanybao/PhishIntention/results/4.12/ori_common_Learned_Logo_Phishing.csv\n",
      "Saved original common DataFrame for 'No_Logo_Phishing' to /home/tiffanybao/PhishIntention/results/4.12/ori_common_No_Logo_Phishing.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the output directory for the CSV files\n",
    "output_dir = \"/home/tiffanybao/PhishIntention/results/4.12\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop over each category in the multi_common_dfs dictionary and save them.\n",
    "for category, df in multi_common_dfs.items():\n",
    "    # Create file name for multimodal common predictions\n",
    "    output_file = os.path.join(output_dir, f\"multi_common_{category}.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved multimodal common DataFrame for '{category}' to {output_file}\")\n",
    "\n",
    "# Loop over each category in the ori_common_dfs dictionary and save them.\n",
    "for category, df in ori_common_dfs.items():\n",
    "    # Create file name for original common predictions\n",
    "    output_file = os.path.join(output_dir, f\"ori_common_{category}.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved original common DataFrame for '{category}' to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29bcde89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site Folder</th>\n",
       "      <th>url</th>\n",
       "      <th>Multimodal_Decision</th>\n",
       "      <th>Image Phish Score</th>\n",
       "      <th>Image_Decision</th>\n",
       "      <th>Text Phish Score</th>\n",
       "      <th>Text_Decision</th>\n",
       "      <th>Image Features</th>\n",
       "      <th>Text Features</th>\n",
       "      <th>Fused Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hatsandcaps.co.uk</td>\n",
       "      <td>https://hatsandcaps.co.uk</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00|0.00|0.66|0.00|0.00|0.00|1.00|0.50|0.02|0...</td>\n",
       "      <td>0.00|0.00|0.00|0.00|0.00|0.00|0.00|0.00|0.00|0...</td>\n",
       "      <td>0.3648|0.0000|0.2398|0.0000|0.0000|0.0000|0.36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzperformance.com</td>\n",
       "      <td>https://zzperformance.com</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00|1.00|0.85|0.00|0.00|0.00|1.00|0.70|0.01|0...</td>\n",
       "      <td>0.00|0.00|0.00|0.00|1.00|0.00|0.00|0.00|0.00|0...</td>\n",
       "      <td>0.2658|0.2658|0.2259|0.0000|0.0000|0.0000|0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google.co.ke</td>\n",
       "      <td>https://google.co.ke</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00|1.00|0.96|0.00|1.00|0.00|1.00|0.80|0.00|0...</td>\n",
       "      <td>0.00|0.00|1.00|0.00|1.00|0.00|0.00|0.00|0.00|0...</td>\n",
       "      <td>0.2547|0.2547|0.2436|0.0000|0.2547|0.0000|0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kannadashaadi.com</td>\n",
       "      <td>https://kannadashaadi.com</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00|0.00|0.75|0.00|0.00|0.00|1.00|0.50|0.01|0...</td>\n",
       "      <td>0.00|0.00|1.00|0.00|0.00|0.00|0.00|0.00|0.00|0...</td>\n",
       "      <td>0.3588|0.0000|0.2675|0.0000|0.0000|0.0000|0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ilpiacenza.it</td>\n",
       "      <td>https://ilpiacenza.it</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00|0.00|0.73|0.00|0.00|0.00|1.00|0.50|0.01|0...</td>\n",
       "      <td>0.00|0.00|0.00|0.00|0.00|0.00|0.00|0.00|0.00|0...</td>\n",
       "      <td>0.3600|0.0000|0.2622|0.0000|0.0000|0.0000|0.36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Site Folder                        url Multimodal_Decision  \\\n",
       "0  hatsandcaps.co.uk  https://hatsandcaps.co.uk              benign   \n",
       "1  zzperformance.com  https://zzperformance.com              benign   \n",
       "2       google.co.ke       https://google.co.ke              benign   \n",
       "3  kannadashaadi.com  https://kannadashaadi.com              benign   \n",
       "4      ilpiacenza.it      https://ilpiacenza.it              benign   \n",
       "\n",
       "   Image Phish Score  Image_Decision  Text Phish Score  Text_Decision  \\\n",
       "0                0.0               0              0.20              0   \n",
       "1                0.0               0              0.24              0   \n",
       "2                0.0               0              0.37              0   \n",
       "3                0.0               0              0.33              0   \n",
       "4                0.0               0              0.20              0   \n",
       "\n",
       "                                      Image Features  \\\n",
       "0  1.00|0.00|0.66|0.00|0.00|0.00|1.00|0.50|0.02|0...   \n",
       "1  1.00|1.00|0.85|0.00|0.00|0.00|1.00|0.70|0.01|0...   \n",
       "2  1.00|1.00|0.96|0.00|1.00|0.00|1.00|0.80|0.00|0...   \n",
       "3  1.00|0.00|0.75|0.00|0.00|0.00|1.00|0.50|0.01|0...   \n",
       "4  1.00|0.00|0.73|0.00|0.00|0.00|1.00|0.50|0.01|0...   \n",
       "\n",
       "                                       Text Features  \\\n",
       "0  0.00|0.00|0.00|0.00|0.00|0.00|0.00|0.00|0.00|0...   \n",
       "1  0.00|0.00|0.00|0.00|1.00|0.00|0.00|0.00|0.00|0...   \n",
       "2  0.00|0.00|1.00|0.00|1.00|0.00|0.00|0.00|0.00|0...   \n",
       "3  0.00|0.00|1.00|0.00|0.00|0.00|0.00|0.00|0.00|0...   \n",
       "4  0.00|0.00|0.00|0.00|0.00|0.00|0.00|0.00|0.00|0...   \n",
       "\n",
       "                                      Fused Features  \n",
       "0  0.3648|0.0000|0.2398|0.0000|0.0000|0.0000|0.36...  \n",
       "1  0.2658|0.2658|0.2259|0.0000|0.0000|0.0000|0.26...  \n",
       "2  0.2547|0.2547|0.2436|0.0000|0.2547|0.0000|0.25...  \n",
       "3  0.3588|0.0000|0.2675|0.0000|0.0000|0.0000|0.35...  \n",
       "4  0.3600|0.0000|0.2622|0.0000|0.0000|0.0000|0.36...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_common_benign_with_logo.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
